# NLP_experiments

I am using an NLP code that uses embeddings in Glove to summarize a Wall Street Journal article that I know very well.
This is in the notebook codeA_0.ipynb where 'A' stands for advanced

For comparison, I am doing the same exercise but this time using a python library that does tokenization.
This is in the notebook code_0.ipynb

# use the code in this site
# https://thecleverprogrammer.com/2020/08/24/summarize-text-with-machine-learning/
#
# the data set is a pdf converted to text from wsj using https://pdftotext.com/
# source - see line below with the url
# https://www.wsj.com/articles/the-day-coronavirus-nearly-broke-the-financial-markets-11589982288

The advanced code does an amazing job of summarization on an article I know very well.

So, even without understanding the implementation details, it is possible to use NLP & achieve practical results.

Perhaps one could optimize the pipeline: in my case, I just converted pdf to text, and then pasted the text output in one cell of the jupyter notebook


